{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb654d3e-7eac-4900-9008-d1f1cb8b2cb7",
   "metadata": {},
   "source": [
    "https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3462aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from urllib.parse import urlparse\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import planetary_computer\n",
    "# import pystac\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e96a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.datasets import RasterDataset, stack_samples, unbind_samples\n",
    "from torchgeo.datasets.utils import download_url\n",
    "from torchgeo.samplers import RandomGeoSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3981f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking both insallations\n",
    "import rasterio as rio\n",
    "import torchgeo\n",
    "\n",
    "from pathlib import  Path\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e70f5-5db7-4491-b2f0-9d22db877f7d",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6f657-2a10-4ba1-9d17-11fcc35c967d",
   "metadata": {},
   "source": [
    "### get paths to train and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2555ab27-5da3-4f55-befb-2f9b2b3a6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(r'C:\\Users\\wenxinyang\\Desktop\\Projects\\iguide\\training_samples')\n",
    "assert root.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abe51a8c-720b-49c8-9434-fad4fa99b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000039.tif\n",
      "000000000133.tif\n",
      "000000000344.tif\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# remove any images with NA values in the dataset\n",
    "n = 0\n",
    "for filename in os.listdir(os.path.join(root, 'images')):\n",
    "    path_file = os.path.join(root, 'images', filename)\n",
    "    file = rio.open(path_file)\n",
    "    test_value = file.read(1).max()\n",
    "    file.close()\n",
    "    if math.isnan(test_value):\n",
    "        print(filename)\n",
    "        n = n + 1\n",
    "        os.remove(os.path.join(root, 'images', filename))\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35c23d2-3dd8-4165-9303-a2758a74f3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ids = [x for x in os.listdir(os.path.join(root, 'images')) if x.endswith('.tif')]\n",
    "len(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aad156e5-06f3-4e2e-aa5d-128b5f5e8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000039.tif\n",
      "000000000133.tif\n",
      "000000000344.tif\n"
     ]
    }
   ],
   "source": [
    "# remove unmatched files\n",
    "for filename in os.listdir(os.path.join(root, 'annotations')):\n",
    "    if filename not in img_ids:\n",
    "        print(filename)\n",
    "        os.remove(os.path.join(root, 'annotations', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e6428b8-cb15-4b9c-8902-52ea4429fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = list((root/'images').glob('*.tif'))\n",
    "train_masks = list((root/'annotations').glob('*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "568188b8-6436-406f-bce4-ecd78beab085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many chips we have \n",
    "len(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1041b148-e8b4-4bcf-8096-d029242a59c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs) == len(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3275f2ff-c06a-402b-9af5-84b9b81b84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the images and corresponding masks are matched by name, we will sort both lists to keep them synchronized.\n",
    "train_imgs.sort(); train_masks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7797654e-3481-405b-a963-e9aa7fa2b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs = (root/'images').as_posix()\n",
    "# it is important to use a projected coordinate system\n",
    "train_ds = RasterDataset(path_imgs, res=30, crs = 'epsg:26918')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6a55d4-c454-4d71-83b1-13430d56b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RasterDataset Dataset\n",
      "    type: GeoDataset\n",
      "    bbox: BoundingBox(minx=-1547075.146921655, maxx=-1437998.5057360458, miny=3426936.12106045, maxy=3526592.039209696, mint=0.0, maxt=9.223372036854776e+18)\n",
      "    size: 415\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb1fb4a-b687-47c1-b08c-952bd8d9c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomGeoSampler(train_ds, size=(255, 255), length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77a09e81-116c-422b-b4a3-5405397ba3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "826e55ca-cdfe-41c7-a584-b8993faa2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = next(iter(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc20e481-6eb3-467b-bc4c-c68477592d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(minx=-1503342.7936045222, maxx=-1495692.7936045222, miny=3451224.8441685433, maxy=3458874.8441685433, mint=0.0, maxt=9.223372036854776e+18)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7cdef85-712f-4bd6-b6d3-dafef10eae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(item: dict):\n",
    "    item['image'] = item['image'] / 10000\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c68ab12e-4b27-4375-a4de-c6fb89be47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = RasterDataset((root/'images').as_posix(), crs='epsg:26918', res=30, transforms=scale)\n",
    "train_msks = RasterDataset((root/'annotations').as_posix(), crs='epsg:26918', res=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83b647e0-2903-40f0-8646-c05ddba11460",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_msks.is_image = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e2297ea-4e69-4739-907f-acac8ea62668",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = train_imgs & train_msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c3daff9-3b2a-4a13-ad46-63560e95e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dset, sampler=sampler, batch_size=8, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad9a3c7a-10f2-4ccd-861c-384549139e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['crs', 'bbox', 'image', 'mask'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a138530-9247-41da-851c-1e881eb29010",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b6fe332-30c8-4334-b86b-799fb786989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "def calc_statistics(dset: RasterDataset):\n",
    "        \"\"\"\n",
    "        Calculate the statistics (mean and std) for the entire dataset\n",
    "        Warning: This is an approximation. The correct value should take into account the\n",
    "        mean for the whole dataset for computing individual stds.\n",
    "        For correctness I suggest checking: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.html\n",
    "        \"\"\"\n",
    "\n",
    "        # To avoid loading the entire dataset in memory, we will loop through each img\n",
    "        # The filenames will be retrieved from the dataset's rtree index\n",
    "        files = [item.object for item in dset.index.intersection(dset.index.bounds, objects=True)]\n",
    "\n",
    "        # Reseting statistics\n",
    "        accum_mean = 0\n",
    "        accum_std = 0\n",
    "\n",
    "        for file in files:\n",
    "            img = rio.open(file).read()/10000 #type: ignore\n",
    "            accum_mean += img.reshape((img.shape[0], -1)).mean(axis=1)\n",
    "            accum_std += img.reshape((img.shape[0], -1)).std(axis=1)\n",
    "\n",
    "        # at the end, we shall have 2 vectors with lenght n=chnls\n",
    "        # we will average them considering the number of images\n",
    "        return accum_mean / len(files), accum_std / len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2297c0d-a550-4582-8477-7e82a8daf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [item.object for item in train_imgs.index.intersection(train_imgs.index.bounds, objects = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "871222e3-037d-4110-bc06-c1285ba3d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01187991 0.01294848 0.01124623 0.01377422] [0.00345638 0.00295712 0.00307989 0.00308207]\n"
     ]
    }
   ],
   "source": [
    "mean, std = calc_statistics(train_imgs)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cb8e381-e6c8-4161-9c31-89724b6b8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalize(torch.nn.Module):\n",
    "    def __init__(self, mean: list[float], stdev: list[float]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mean = torch.Tensor(mean)[:, None, None]\n",
    "        self.std = torch.Tensor(stdev)[:, None, None]\n",
    "\n",
    "    def forward(self, inputs: dict):\n",
    "\n",
    "        x = inputs[\"image\"][..., : len(self.mean), :, :]\n",
    "\n",
    "        # if batch\n",
    "        if inputs[\"image\"].ndim == 4:\n",
    "            x = (x - self.mean[None, ...]) / self.std[None, ...]\n",
    "\n",
    "        else:\n",
    "            x = (x - self.mean) / self.std\n",
    "\n",
    "        inputs[\"image\"][..., : len(self.mean), :, :] = x\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def revert(self, inputs: dict):\n",
    "        \"\"\"\n",
    "        De-normalize the batch.\n",
    "        Args:\n",
    "            inputs (dict): Dictionary with the 'image' key\n",
    "        \"\"\"\n",
    "\n",
    "        x = inputs[\"image\"][..., : len(self.mean), :, :]\n",
    "\n",
    "        # if batch\n",
    "        if x.ndim == 4:\n",
    "            x = inputs[\"image\"][:, : len(self.mean), ...]\n",
    "            x = x * self.std[None, ...] + self.mean[None, ...]\n",
    "        else:\n",
    "            x = x * self.std + self.mean\n",
    "\n",
    "        inputs[\"image\"][..., : len(self.mean), :, :] = x\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4bcc7a0-3fbf-430b-bbe1-9483babae531",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = MyNormalize(mean=mean, stdev=std)\n",
    "norm_batch = normalize(batch)\n",
    "# plot_batch(norm_batch)\n",
    "\n",
    "batch = normalize.revert(norm_batch)\n",
    "# plot_batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965dca5e-f75f-429e-83ca-f0c28de8e8a4",
   "metadata": {},
   "source": [
    "### Let's skip adding spectral index for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fb1f786-3ed0-4842-8532-2f1db435451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.transforms import AppendNDVI\n",
    "\n",
    "ndvi_transform = AppendNDVI(index_red=0, index_nir=3)\n",
    "# print(transformed_batch['image'].shape, transformed_batch['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d08004fb-accd-42a7-9430-ea0b8018428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 255, 255]) torch.Size([8, 1, 255, 255])\n"
     ]
    }
   ],
   "source": [
    "print(norm_batch['image'].shape, norm_batch['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b5c63bd-cc7f-4253-af87-a711092b58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0_path = os.path.join(root, 'images', '000000000017.tif')\n",
    "img0 = rio.open(img0_path)\n",
    "img0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45997b55-97a5-4072-8c9a-d56a86f6f7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchgeo.transforms.indices.AppendNDVI"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ndvi_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68a53069-239a-4649-b381-cd22ddde7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_batch = ndvi_transform(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393af25-32cc-4961-a691-db9a6b0906cb",
   "metadata": {},
   "source": [
    "## Segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e48dcf98-17cc-4b55-9900-f9fa3433e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\wenxinyang/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:01<00:00, 96.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "model = deeplabv3_resnet50(weights=None, num_classes=2)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5bbd08b-4280-4668-b5e3-a756b943f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = model.get_submodule('backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7049dbf3-6301-4abc-8772-05549ddfe555",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.modules.conv.Conv2d(\n",
    "    in_channels=4, \n",
    "    out_channels=64, \n",
    "    kernel_size=(7, 7),\n",
    "    stride=(2, 2),\n",
    "    padding=(3, 3),\n",
    "    bias=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "787743ba-3f76-4090-a252-085998a1c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.register_module('conv1', conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edda2102-45dd-4b13-b3a9-ab5419a5ce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 255, 255])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(torch.randn(3, 4, 255, 255))\n",
    "pred['out'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac956dd-7dfa-46f6-97d1-e5d87d0a0afb",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "babc51f0-3fee-4d8c-89ac-7886424e944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2abf1c7f-3ad0-4eb1-b9a2-638899027fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    epochs: int, \n",
    "    train_dl: DataLoader, \n",
    "    val_dl: Optional[DataLoader], \n",
    "    model: torch.nn.Module, \n",
    "    loss_fn: Callable, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    acc_fns: Optional[list]=None, \n",
    "    batch_tfms: Optional[Callable]=None\n",
    "):\n",
    "    # size = len(dataloader.dataset)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    cuda_model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        accum_loss = 0\n",
    "        for batch in train_dl:\n",
    "\n",
    "            if batch_tfms is not None:\n",
    "                batch = batch_tfms(batch)\n",
    "\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['mask'].type(torch.long).to(device)\n",
    "            pred = cuda_model(X)['out']\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # BackProp\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update the accum loss\n",
    "            accum_loss += float(loss) / len(train_dl)\n",
    "\n",
    "        # Testing against the validation dataset\n",
    "        if acc_fns is not None and val_dl is not None:\n",
    "            # reset the accuracies metrics\n",
    "            acc = [0.] * len(acc_fns)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dl:\n",
    "\n",
    "                    if batch_tfms is not None:\n",
    "                        batch = batch_tfms(batch)                    \n",
    "\n",
    "                    X = batch['image'].type(torch.float32).to(device)\n",
    "                    y = batch['mask'].type(torch.long).to(device)\n",
    "\n",
    "                    pred = cuda_model(X)['out']\n",
    "\n",
    "                    for i, acc_fn in enumerate(acc_fns):\n",
    "                        acc[i] = float(acc[i] + acc_fn(pred, y)/len(val_dl))\n",
    "\n",
    "            # at the end of the epoch, print the errors, etc.\n",
    "            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f} - Accs={[round(a, 3) for a in acc]}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca2b18-a3e6-4af0-bb9c-d05215e6f00f",
   "metadata": {},
   "source": [
    "## Loss and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be7221e7-9cd8-4815-bba8-36e605dbf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def oa(pred, y):\n",
    "    flat_y = y.squeeze()\n",
    "    flat_pred = pred.argmax(dim=1)\n",
    "    acc = torch.count_nonzero(flat_y == flat_pred) / torch.numel(flat_y)\n",
    "    return acc\n",
    "\n",
    "def iou(pred, y):\n",
    "    flat_y = y.cpu().numpy().squeeze()\n",
    "    flat_pred = pred.argmax(dim=1).detach().cpu().numpy()\n",
    "    return jaccard_score(flat_y.reshape(-1), flat_pred.reshape(-1), zero_division=1.)    \n",
    "\n",
    "def loss(p, t):    \n",
    "    return torch.nn.functional.cross_entropy(p, t.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff8f4c-9dbb-4afe-8c14-81a3561c7092",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a52413af-b858-482e-8f92-fdc5e18063e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b656bf8-2da1-4a53-b20c-910dab4632f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=0.73250\n",
      "Epoch 1: Train Loss=0.70910\n"
     ]
    }
   ],
   "source": [
    "train_loop(2, dataloader, None, model, loss, optimizer, \n",
    "           acc_fns=[oa, iou], batch_tfms=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
